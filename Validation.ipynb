{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koogk7/ML_perfect_guide/blob/master/Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swq7_iUL2R4W",
        "colab_type": "text"
      },
      "source": [
        "# 교차검증\n",
        "- 테스트 셋 외에 별도의 검증 셋을 만들어 최종평가 이전에 학습된 모델을 다양하게 평가하여 오버피팅을 예방\n",
        "\n",
        "##K 폴드 교차검증\n",
        "  - K개의 데이터 폴드 셋을 만들어서 K번만큼 각 폴트 셋에 학습과 검증 평가를 반복적으로 수행하는 방법\n",
        "  - 하나의 데이터 셋을 K개로 나누는 것이 아니라, 하나의 데이터 셋에 대해 총 K개의 학습 데이터와 검증데이터 셋의 조합을 만드는 것이다.\n",
        " *이탤릭체 텍스트*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCJDqCSj3IYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wWBPi_z3jDt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37ccddfb-f8f0-47b0-ecbe-67848ebcd1b0"
      },
      "source": [
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "df_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:', features.shape[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFjDxM7z4j1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7170fd5c-4065-4dbc-e9c4-53c5e281395e"
      },
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index, in kfold.split(features):\n",
        "\n",
        "  # 데이터 분리\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  \n",
        "  # 학습 및 예측\n",
        "  df_clf.fit(X_train, y_train)\n",
        "  pred = df_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "  \n",
        "  # 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print(\"\\n#{0} 교차 검증 정확도 : {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}\".format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "  \n",
        "# iter별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도 : 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도 : 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도 : 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도 : 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도 : 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwjIkzlB9K4H",
        "colab_type": "text"
      },
      "source": [
        "## ------------------------------------------------\n",
        "## Stratified K 폴드\n",
        "\n",
        "- Stratified K 폴드는 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식\n",
        "- 대출 사기 데이터를 예측한다고 생각해보자, 대부분의 데이터는 정상적이며 일부의 데이터만 사기 데이터일 것이다. 이 때 K 폴드로 랜덤하게 학습 및 테스트 셋을 나눌때 정상적인 데이터와 사기 데이터의 비율이 제대로 반영 되지 않는 경우가 쉽게 발생한다. \n",
        "- Stratified K 폴드는 원본 데이터의 레이블 분포를 먼저 고려한 뒤 이 분포와 동일하게 학습 및 검증 데이터를 분배한다.\n",
        "- 일반적으로 분류에서의 교차 검증은 K 폴드가 아닌 Stratified K 폴드로 분할되야 한다. 반면 회귀에서는 결정값이 이산값이 아닌 연속된 숫자값이기때문에 결정값의 분포가 의미가 없음으로 Stratified K 폴드를 지원되지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDCHcu-f-dnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "d8bdc1e9-b724-474c-e5a7-763ed0a6fa62"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd \n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "iris_df = pd.DataFrame(data=features, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "n_iter=0\n",
        "\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter +=1\n",
        "  label_train= iris_df['label'].iloc[train_index] # iloc 인자로 배열도 올 수 있다.\n",
        "  label_test= iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())  \n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    33\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "1    17\n",
            "0    17\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 2    33\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "1    17\n",
            "0    17\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "1    34\n",
            "0    34\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    16\n",
            "1    16\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LzwQGSwBxiA",
        "colab_type": "text"
      },
      "source": [
        "## ------------------------------------------------\n",
        "## 교차 검증을 보다 간편하게 - cross_val_score()\n",
        "- 위 과정을 요약하면 아래와 같다.\n",
        "  1. 폴드셋 설정\n",
        "  2. for 루프에서 반복적으로 학습 및 테스트 데이터 인덱스 추출\n",
        "  3. 학습 예측 수행 및 예측성능 반환\n",
        "- cross_val_score()는 위 과정을 한번에 수행해주는 API이다. 다음은 함수 선언 형태이다\n",
        "    - ***cross_val_score(estimator, X , y=None, scroing=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')***  \n",
        "    - estimator는 사이킷런의 알고리즘, X는 피처데이터, y는 레이블 데이터, scoring은 예측성능평가지표, cv는 교차 검증 폴드 수를 의미, 함수는 수행 후 scoring로 지정된 성능 지표 측정값을 배열 형태로 반환\n",
        "    - estimator 가 분류일 경우 Stratified K 폴드, 회귀일 경우 K폴드가 수행된다.\n",
        "- cross_validate()는 여러개의 평가 지표를 반환 할 수 있다. 또한 수행시간도 같이 제공\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nYbnyA0DlLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d7753c92-a0c5-4cf1-ab59-a00f50f5f9d5"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "\n",
        "scores = cross_val_score(df_clf, iris.data, label, scoring='accuracy', cv=3)\n",
        "print('교차 검증별 정확도:', np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.9804 0.9216 0.9792]\n",
            "평균 검증 정확도: 0.9604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N86U-e0tFt3X",
        "colab_type": "text"
      },
      "source": [
        "## ------------------------------------------------\n",
        "## GridSearchCV - 교차 검증을 통한 하이퍼 파라미터 튜닝\n",
        "\n",
        "- 교차 검증을 기반으로 하이퍼 파라미터의 최적 값을 찾아준다.  단 주어진 하이퍼 파라미터 조합을 모두 검사하기때문에 상대적으로 시간이 오래 걸린다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gB7fv3YGWax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "253ecb4f-0b92-4284-a8cb-c4a794c8cbc8"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "iris_data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                   test_size=0.2, random_state=121)\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "# 파라미터를 딕셔너리 형태로 설정\n",
        "params = {'max_depth':[1, 2, 3], 'min_samples_split': [2, 3]}\n",
        "\n",
        "# refit=True가 디폴트, True이면 가장 좋은 파라미터 설정으로 재학습시킴\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=params, refit=True)\n",
        "\n",
        "# 학습데이터로 params의 하이퍼 파라미터를 순차적으로 학습/평가\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
        "          'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  ...  split2_test_score\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}  ...               0.70\n",
              "1  {'max_depth': 1, 'min_samples_split': 3}  ...               0.70\n",
              "2  {'max_depth': 2, 'min_samples_split': 2}  ...               0.95\n",
              "3  {'max_depth': 2, 'min_samples_split': 3}  ...               0.95\n",
              "4  {'max_depth': 3, 'min_samples_split': 2}  ...               0.95\n",
              "5  {'max_depth': 3, 'min_samples_split': 3}  ...               0.95\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMdtiKKdIoOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "295b489f-3e1e-4e6b-e7a6-85489909978a"
      },
      "source": [
        "print('최적 파라미터:', grid_dtree.best_params_)\n",
        "print('최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "최고 정확도:0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfMeWcUcJEPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1b5a715-9c9e-4f65-9657-54e7c85fb84f"
      },
      "source": [
        "# refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "pred = estimator.predict(X_test) # 학습이 되어있음므로 별도의 학습이 필요없다.\n",
        "print(\"테스트 데이터 셋 정확도: {0: .4f}\".format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 셋 정확도:  0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}